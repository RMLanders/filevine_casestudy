{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import marqo\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/full_drop.csv')\n",
    "model = \"hf/multilingual-e5-large\"\n",
    "url = \"http://localhost:8882\"\n",
    "mq = marqo.Client(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count = df.isna().sum()\n",
    "\n",
    "print(nan_count)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/full_one_hot_encoded.csv')\n",
    "\n",
    "def clean_text(txt):\n",
    "    if pd.isna(txt):\n",
    "        clean_text = \"\"\n",
    "    else:   \n",
    "        soup = BeautifulSoup(str(txt).strip(), 'html.parser')\n",
    "        clean_text = soup.get_text()\n",
    "        clean_text = re.sub('[^a-zA-Z0-9\\s]', '', clean_text)\n",
    "        clean_text = clean_text.lower()\n",
    "    return clean_text\n",
    "\n",
    "df['facts_clean'] = df['facts'].apply(clean_text)\n",
    "df['issue_area'] = df['issue_area'].apply(clean_text)\n",
    "df['legal_question'] = df['legal_question'].apply(clean_text)\n",
    "df['conclusion'] = df['conclusion'].apply(clean_text)\n",
    "\n",
    "df['sim1_facts_score'] = None\n",
    "df['sim1_issue_area_score'] = None\n",
    "df['sim1_legal_question_score'] = None\n",
    "df['sim1_conclusion_score'] = None\n",
    "\n",
    "df['sim2_facts_score'] = None\n",
    "df['sim2_issue_area_score'] = None\n",
    "\n",
    "df['sim1_facts_href'] = None\n",
    "df['sim2_facts_href'] = None\n",
    "\n",
    "df['sim1_issue_area_href'] = None\n",
    "df['sim2_issue_area_href'] = None\n",
    "\n",
    "df['sim1_legal_question_href'] = None\n",
    "\n",
    "df['sim1_conclusion_href'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['facts'] == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count = df.isna().sum()\n",
    "\n",
    "print(nan_count)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['href']==search_href]['sim3_facts_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[[df['href']==search_href]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['href']=='https://api.oyez.org/cases/1984/83-1919']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tqdm(df.iterrows()):\n",
    "    search_href = row['href']\n",
    "    # facts = row['facts_clean']\n",
    "    # results = mq.index(\"whole\").search(facts, search_method='TENSOR')\n",
    "    # results_df = pd.DataFrame(results['hits'])\n",
    "    # same_doc_index = results_df[results_df['href']==search_href].index\n",
    "    # results_df.drop(same_doc_index , inplace=True)\n",
    "    # results_df[0:3]\n",
    "\n",
    "    facts = row['facts_clean']\n",
    "    print(\"===============\")\n",
    "    print(index)\n",
    "    print(facts)\n",
    "    print(search_href)\n",
    "    print(\"===============\")\n",
    "    results = mq.index(\"whole_legal\").search(facts, search_method='TENSOR')\n",
    "    results_df = pd.DataFrame(results['hits'])\n",
    "    same_doc_index = results_df[results_df['href']==search_href].index\n",
    "    results_df.drop(same_doc_index , inplace=True)\n",
    "    results_df = results_df[0:3]\n",
    "    print(results_df[['href', '_score']])\n",
    "    df.loc[df['href']==search_href, 'sim1_facts_score'] = results_df['_score'].iloc[0]\n",
    "    df.loc[df['href']==search_href, 'sim2_facts_score'] = results_df['_score'].iloc[1]\n",
    "\n",
    "    df.loc[df['href']==search_href, 'sim1_facts_href'] = results_df['href'].iloc[0]\n",
    "    df.loc[df['href']==search_href, 'sim2_facts_href'] = results_df['href'].iloc[1]\n",
    "    print(\"===============\")\n",
    "    print(results_df['_score'].iloc[0])\n",
    "    print(results_df['_score'].iloc[1])\n",
    "    print(results_df['_score'].iloc[2])\n",
    "    print(\"***********************\")\n",
    "    print(df[df['href']==search_href]['sim1_facts_score'])\n",
    "    print(df[df['href']==search_href]['sim2_facts_score'])\n",
    "\n",
    "    print(df[df['href']==search_href]['sim1_facts_href'])\n",
    "    print(df[df['href']==search_href]['sim2_facts_href'])\n",
    "    print(\"===============\")\n",
    "    print(\"===============\")\n",
    "    print(\"===============\")\n",
    "\n",
    "    issue_area = row['issue_area']\n",
    "    print(\"===============\")\n",
    "    print(index)\n",
    "    print(issue_area)\n",
    "    print(search_href)\n",
    "    print(\"===============\")\n",
    "    results = mq.index(\"whole_legal\").search(issue_area, search_method='TENSOR')\n",
    "    results_df = pd.DataFrame(results['hits'])\n",
    "    same_doc_index = results_df[results_df['href']==search_href].index\n",
    "    results_df.drop(same_doc_index , inplace=True)\n",
    "    results_df = results_df[0:3]\n",
    "    print(results_df[['href', '_score']])\n",
    "    df.loc[df['href']==search_href, 'sim1_issue_area_score'] = results_df['_score'].iloc[0]\n",
    "    df.loc[df['href']==search_href, 'sim2_issue_area_score'] = results_df['_score'].iloc[1]\n",
    "\n",
    "    df.loc[df['href']==search_href, 'sim1_issue_area_href'] = results_df['href'].iloc[0]\n",
    "    df.loc[df['href']==search_href, 'sim2_issue_area_href'] = results_df['href'].iloc[1]\n",
    "    print(\"===============\")\n",
    "    print(results_df['_score'].iloc[0])\n",
    "    print(results_df['_score'].iloc[1])\n",
    "    print(\"***********************\")\n",
    "    print(df[df['href']==search_href]['sim1_issue_area_score'])\n",
    "    print(df[df['href']==search_href]['sim2_issue_area_score'])\n",
    "\n",
    "    print(df[df['href']==search_href]['sim1_issue_area_href'])\n",
    "    print(df[df['href']==search_href]['sim2_issue_area_href'])\n",
    "    print(\"===============\")\n",
    "    print(\"===============\")\n",
    "    print(\"===============\")\n",
    "\n",
    "    legal_question = row['legal_question']\n",
    "    print(\"===============\")\n",
    "    print(index)\n",
    "    print(legal_question)\n",
    "    print(search_href)\n",
    "    print(\"===============\")\n",
    "    results = mq.index(\"whole_legal\").search(legal_question, search_method='TENSOR')\n",
    "    results_df = pd.DataFrame(results['hits'])\n",
    "    same_doc_index = results_df[results_df['href']==search_href].index\n",
    "    results_df.drop(same_doc_index , inplace=True)\n",
    "    results_df = results_df[0:3]\n",
    "    print(results_df[['href', '_score']])\n",
    "    df.loc[df['href']==search_href, 'sim1_legal_question_score'] = results_df['_score'].iloc[0]\n",
    "\n",
    "    df.loc[df['href']==search_href, 'sim1_legal_question_href'] = results_df['href'].iloc[0]\n",
    "    print(\"===============\")\n",
    "    print(results_df['_score'].iloc[0])\n",
    "    print(\"***********************\")\n",
    "    print(df[df['href']==search_href]['sim1_legal_question_score'])\n",
    "\n",
    "    print(df[df['href']==search_href]['sim1_legal_question_href'])\n",
    "    print(\"===============\")\n",
    "    print(\"===============\")\n",
    "    print(\"===============\")\n",
    "\n",
    "    conclusion = row['conclusion']\n",
    "    print(\"===============\")\n",
    "    print(index)\n",
    "    print(conclusion)\n",
    "    print(search_href)\n",
    "    print(\"===============\")\n",
    "    results = mq.index(\"whole_legal\").search(conclusion, search_method='TENSOR')\n",
    "    results_df = pd.DataFrame(results['hits'])\n",
    "    same_doc_index = results_df[results_df['href']==search_href].index\n",
    "    results_df.drop(same_doc_index , inplace=True)\n",
    "    results_df = results_df[0:3]\n",
    "    print(results_df[['href', '_score']])\n",
    "    df.loc[df['href']==search_href, 'sim1_conclusion_score'] = results_df['_score'].iloc[0]\n",
    "\n",
    "    df.loc[df['href']==search_href, 'sim1_conclusion_href'] = results_df['href'].iloc[0]\n",
    "    print(\"===============\")\n",
    "    print(results_df['_score'].iloc[0])\n",
    "    print(\"***********************\")\n",
    "    print(df[df['href']==search_href]['sim1_conclusion_score'])\n",
    "\n",
    "    print(df[df['href']==search_href]['sim1_conclusion_href'])\n",
    "    print(\"===============\")\n",
    "    print(\"===============\")\n",
    "    print(\"===============\")\n",
    "\n",
    "    # for index, row in results_df[0:3].iterrows():\n",
    "    #     document_id = row['_id']\n",
    "    #     doc = mq.index(\"whole\").get_document(\n",
    "    #         document_id=document_id,\n",
    "    #         expose_facets=True\n",
    "    #     )\n",
    "                \n",
    "        # facets = doc['_tensor_facets']\n",
    "        # for i in range(len(doc['_tensor_facets'])):\n",
    "        #     field = list(facets[i].keys())[0]\n",
    "        #     embedding = facets[i]['_embedding']\n",
    "        #     print(field)\n",
    "\n",
    "        # df.loc[df['href']==row['href'], f'sim{index}_{field}_vector'] = str(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count = df.isna().sum()\n",
    "\n",
    "print(nan_count)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in tqdm(df.iterrows()):\n",
    "#     search_href = row['href']\n",
    "#     facts = row['facts_clean']\n",
    "#     results = mq.index(\"sentences\").search(facts, search_method='TENSOR')\n",
    "#     results_df = pd.DataFrame(results['hits'])\n",
    "#     same_doc_index = results_df[results_df['href']==search_href].index\n",
    "#     results_df.drop(same_doc_index , inplace=True)\n",
    "#     results_df[0:3]\n",
    "\n",
    "#     df.loc[df['href']==search_href, 'sim1_score_sent']=results_df['_score'].iloc[0]\n",
    "#     df.loc[df['href']==search_href, 'sim1_href_sent'] = results_df['href'].iloc[0]\n",
    "#     df.loc[df['href']==search_href, 'sim2_score_sent'] = results_df['_score'].iloc[1]\n",
    "#     df.loc[df['href']==search_href, 'sim2_href_sent'] = results_df['href'].iloc[1]\n",
    "#     df.loc[df['href']==search_href, 'sim3_score_sent'] = results_df['_score'].iloc[2]\n",
    "#     df.loc[df['href']==search_href, 'sim3_href_sent'] = results_df['href'].iloc[2]\n",
    "\n",
    "#     for index, row in results_df[0:3].iterrows():\n",
    "#         document_id = row['_id']\n",
    "#         facets = mq.index(\"full_orig_model_filevine_docs_sentences\").get_document(\n",
    "#             document_id=document_id,\n",
    "#             expose_facets=True\n",
    "#         )\n",
    "\n",
    "#         df.loc[df['href']==row['href'], f'sim{index}_vector_sent'] = str(facets['_tensor_facets'][0]['_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "  \n",
    "# Create a variable \n",
    "\n",
    "  \n",
    "# Open a file and use dump() \n",
    "with open('df_final.pkl', 'wb') as file: \n",
    "    # A new file will be created \n",
    "    pickle.dump(df, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import marqo\n",
    "\n",
    "# url = \"http://localhost:8882\"\n",
    "# mq = marqo.Client(url=url)\n",
    "\n",
    "# doc = mq.index(\"whole\").get_document(\n",
    "#     document_id=\"00295e5d-1860-45dd-96a9-e410e13fe233\",\n",
    "#     expose_facets=True\n",
    "# )\n",
    "# doc['_tensor_facets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc['_tensor_facets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facets = doc['_tensor_facets']\n",
    "# for index in range(len(doc['_tensor_facets'])):\n",
    "#     print(index)\n",
    "#     print(list(facets[index].keys())[0])\n",
    "#     print(facets[index]['_embedding'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
